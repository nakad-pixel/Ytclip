name: AutoClip Gaming Pipeline - Two Phase

on:
  schedule:
    # Phase 1 Analysis: Every 6 hours
    - cron: '0 */6 * * *'
    # Phase 2 Creation: Every 12 hours (at midnight and noon UTC)
    - cron: '0 0,12 * * *'
  workflow_dispatch:
    inputs:
      phase:
        description: 'Phase to run'
        required: true
        type: choice
        options:
          - analysis
          - creation
          - both

env:
  PYTHON_VERSION: '3.10'

jobs:
  # Discovery job runs before analysis
  discover:
    runs-on: ubuntu-latest
    # Only run on scheduled events or manual dispatch with both/analysis
    if: github.event_name == 'schedule' || github.event.inputs.phase == 'both' || github.event.inputs.phase == 'analysis'
    outputs:
      videos_count: ${{ steps.extract_videos.outputs.videos_count }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg jq
      
      - name: Install Python dependencies
        run: pip install -r requirements.txt
      
      - name: Validate YouTube API Key
        run: |
          if [ -z "${{ secrets.YOUTUBE_API_KEY }}" ]; then
            echo "âŒ ERROR: YOUTUBE_API_KEY secret is not set!"
            echo "Please add YOUTUBE_API_KEY to GitHub Secrets"
            exit 1
          fi
          echo "âœ“ YouTube API Key is set"
      
      - name: Run discovery
        id: discovery
        run: python src/discovery.py
        env:
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
      
      - name: Extract videos count
        id: extract_videos
        run: |
          if [ ! -f data/discovered_videos.json ]; then
            echo "âŒ ERROR: discovery.py did not create discovered_videos.json"
            echo "videos_count=0" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # Get count
          count=$(jq length data/discovered_videos.json 2>/dev/null || echo "0")
          echo "videos_count=${count}" >> $GITHUB_OUTPUT
          echo "âœ“ Discovered ${count} videos"
      
      - name: Upload database artifact
        uses: actions/upload-artifact@v4
        with:
          name: discovery-database
          path: data/videos.db
          if-no-files-found: ignore

  # Phase 1: Analysis - runs every 6 hours
  analyze-videos:
    needs: discover
    runs-on: ubuntu-latest
    # Run on schedule at 6-hour intervals OR manual dispatch
    if: |
      (github.event_name == 'schedule' && github.event.schedule == '0 */6 * * *') ||
      github.event.inputs.phase == 'analysis' ||
      github.event.inputs.phase == 'both'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
      
      - name: Install Python dependencies
        run: pip install -r requirements.txt
      
      - name: Install Playwright browsers
        run: python -m playwright install --with-deps chromium
      
      - name: Download database artifact
        uses: actions/download-artifact@v4
        with:
          name: discovery-database
          path: data/
        continue-on-error: true
      
      - name: Run Phase 1 Analysis
        run: python src/processor.py --phase analysis
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      
      - name: Upload analysis results
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results
          path: |
            data/phase_analysis_results.json
            data/videos.db
          if-no-files-found: ignore
      
      - name: Display analysis summary
        if: always()
        run: |
          if [ -f data/phase_analysis_results.json ]; then
            echo "ðŸ“Š Analysis Results:"
            jq -r '"Videos analyzed: \(.videos_analyzed)\nAbove threshold: \(.videos_above_threshold)\nFailures: \(.failures)"' data/phase_analysis_results.json
          fi

  # Phase 2: Creation - runs every 12 hours
  process-and-publish:
    runs-on: ubuntu-latest
    # Run on schedule at 12-hour intervals OR manual dispatch
    if: |
      (github.event_name == 'schedule' && github.event.schedule == '0 0,12 * * *') ||
      github.event.inputs.phase == 'creation' ||
      github.event.inputs.phase == 'both'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
      
      - name: Install Python dependencies
        run: pip install -r requirements.txt
      
      - name: Install Playwright browsers
        run: python -m playwright install --with-deps chromium
      
      - name: Download analysis database
        uses: actions/download-artifact@v4
        with:
          name: analysis-results
          path: data/
        continue-on-error: true
      
      - name: Run Phase 2 Creation
        run: python src/processor.py --phase creation
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
      
      - name: Upload processing results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: creation-results
          path: |
            data/phase_creation_results.json
            data/clips/
            data/videos.db
          if-no-files-found: ignore
      
      - name: Display creation summary
        if: always()
        run: |
          if [ -f data/phase_creation_results.json ]; then
            echo "ðŸŽ¬ Creation Results:"
            jq -r '"Videos processed: \(.videos_processed)\nClips generated: \(.clips_generated)\nFailures: \(.failures)"' data/phase_creation_results.json
          fi
      
      - name: Smart Publishing
        if: success()
        run: python src/publisher.py
        env:
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
          TIKTOK_ACCESS_TOKEN: ${{ secrets.TIKTOK_ACCESS_TOKEN }}
          INSTAGRAM_ACCESS_TOKEN: ${{ secrets.INSTAGRAM_ACCESS_TOKEN }}
        continue-on-error: true
      
      - name: Upload publishing state
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: publishing-state
          path: data/publishing_state.json
          if-no-files-found: ignore

  # Cleanup job - runs after all jobs complete
  cleanup:
    if: always()
    needs: [discover, analyze-videos, process-and-publish]
    runs-on: ubuntu-latest
    
    steps:
      - name: Delete old artifacts
        uses: geekyeggo/delete-artifact@v2
        with:
          name: |
            discovery-database
            analysis-results
            creation-results
          failOnError: false
